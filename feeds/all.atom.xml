<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Thinking</title><link href="http://puluto.github.io/" rel="alternate"></link><link href="http://puluto.github.io/feeds/all.atom.xml" rel="self"></link><id>http://puluto.github.io/</id><updated>2016-11-25T18:52:00+08:00</updated><entry><title>测试文档</title><link href="http://puluto.github.io/ce-shi-wen-dang.html" rel="alternate"></link><published>2016-11-25T18:52:00+08:00</published><updated>2016-11-25T18:52:00+08:00</updated><author><name>Puluto</name></author><id>tag:puluto.github.io,2016-11-25:/ce-shi-wen-dang.html</id><summary type="html">&lt;h3&gt;单独获取当前目录名&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;name&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getcwd&lt;/span&gt;&lt;span class="p"&gt;())[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;WIN关闭一个进程&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;ctypes&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;kill&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pid&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;kill function for Win32&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;kernel32&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ctypes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;windll&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;kernel32&lt;/span&gt;
    &lt;span class="n"&gt;handle&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;kernel32&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OpenProcess&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pid&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;#使用termina函数结束进程&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;kernel32&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TerminateProcess&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;h3&gt;单独获取当前目录名&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;name&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getcwd&lt;/span&gt;&lt;span class="p"&gt;())[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;WIN关闭一个进程&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;ctypes&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;kill&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pid&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;kill function for Win32&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;kernel32&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ctypes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;windll&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;kernel32&lt;/span&gt;
    &lt;span class="n"&gt;handle&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;kernel32&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;OpenProcess&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pid&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="c1"&gt;#使用termina函数结束进程&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;kernel32&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TerminateProcess&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;handle&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="python"></category></entry><entry><title>基于Centos6安装docker swarm集群</title><link href="http://puluto.github.io/ji-yu-centos6an-zhuang-docker-swarmji-qun.html" rel="alternate"></link><published>2015-12-09T18:52:00+08:00</published><updated>2015-12-09T18:52:00+08:00</updated><author><name>Puluto</name></author><id>tag:puluto.github.io,2015-12-09:/ji-yu-centos6an-zhuang-docker-swarmji-qun.html</id><summary type="html">&lt;h3&gt;升级内核到3.8以上&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;rpm&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;https&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;www&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elrepo&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;org&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;RPM&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;GPG&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;KEY&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;elrepo&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;org&lt;/span&gt;

&lt;span class="n"&gt;rpm&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ivh&lt;/span&gt; &lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;www&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elrepo&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;org&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;elrepo&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;release&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;5.&lt;/span&gt;&lt;span class="n"&gt;el6&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elrepo&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;noarch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rpm&lt;/span&gt;

&lt;span class="c1"&gt;#安装3.10长期支持内核kernel-lt (lt=long-term)&lt;/span&gt;
&lt;span class="n"&gt;yum&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;enablerepo&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;elrepo&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;kernel&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;kernel&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;lt&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;

&lt;span class="c1"&gt;#或者安装主线kernel-ml (ml=mainline)&lt;/span&gt;
&lt;span class="n"&gt;yum&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;enablerepo&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;elrepo&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;kernel&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;kernel&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ml&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;y …&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;h3&gt;升级内核到3.8以上&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;rpm&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;https&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;www&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elrepo&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;org&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;RPM&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;GPG&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;KEY&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;elrepo&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;org&lt;/span&gt;

&lt;span class="n"&gt;rpm&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ivh&lt;/span&gt; &lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="n"&gt;www&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elrepo&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;org&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;elrepo&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;release&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mf"&gt;5.&lt;/span&gt;&lt;span class="n"&gt;el6&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;elrepo&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;noarch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rpm&lt;/span&gt;

&lt;span class="c1"&gt;#安装3.10长期支持内核kernel-lt (lt=long-term)&lt;/span&gt;
&lt;span class="n"&gt;yum&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;enablerepo&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;elrepo&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;kernel&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;kernel&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;lt&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;

&lt;span class="c1"&gt;#或者安装主线kernel-ml (ml=mainline)&lt;/span&gt;
&lt;span class="n"&gt;yum&lt;/span&gt; &lt;span class="o"&gt;--&lt;/span&gt;&lt;span class="n"&gt;enablerepo&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;elrepo&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;kernel&lt;/span&gt; &lt;span class="n"&gt;install&lt;/span&gt; &lt;span class="n"&gt;kernel&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;ml&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Install Docker Service.&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;curl -sSL https://get.docker.com/ &lt;span class="p"&gt;|&lt;/span&gt; sh
&lt;span class="c1"&gt;#国内安装，daocloud加速&lt;/span&gt;
curl -sSL https://get.daocloud.io/docker &lt;span class="p"&gt;|&lt;/span&gt; sh
&lt;span class="c1"&gt;#检查安装结果&lt;/span&gt;
sudo service docker status
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;安装docker的更多内容请参见: &lt;a href="http://docs.docker.com/engine/installation/"&gt;Docker官方安装文档&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;修改docker配置&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;#默认情况下docker守护进程是不会绑定tcp端口的，使用swarm需要开启tcp端口&lt;/span&gt;
&amp;gt; vim /etc/sysconfig/docker
&lt;span class="c1"&gt;#默认配置&lt;/span&gt;
&lt;span class="nv"&gt;other_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="c1"&gt;#修改后的配置&lt;/span&gt;
&lt;span class="nv"&gt;other_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;-H tcp://0.0.0.0:2375 -H unix:///var/run/docker.sock&amp;quot;&lt;/span&gt;
&amp;gt; sudo service docker restart
&lt;span class="c1"&gt;#检查2375端口是否存在&lt;/span&gt;
&amp;gt; netstat -nltp ｜ grep &lt;span class="m"&gt;2375&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;配置swarm&lt;/h3&gt;
&lt;p&gt;Swarm支持多种发现节点的模式，在此介绍本地发现(hosted discovery service)和consul发现两种模式&lt;/p&gt;
&lt;h4&gt;本地发现模式&lt;/h4&gt;
&lt;p&gt;本地模式的原理是提交这个token到docker公司的服务器，然后运行swarm时去查询docker公司的服务器，
因为众所周知的原因，连接docker hub都很慢，所以这种方式不稳定，使用也不够灵活，只适用于测试以
及体验swarm的功能，当然好处是简单，不用引入其他技术。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;#执行swarm获得一个机群token，后续节点的加入均需要这个token&lt;/span&gt;
&amp;gt; sudo docker run swarm create
be1d6ac91667632d6635ee53b1f8caed
&lt;span class="c1"&gt;#在每台需要加入同一swarm机群的节点上运行下面的命令&lt;/span&gt;
&amp;gt; docker run -d swarm join --addr&lt;span class="o"&gt;=&lt;/span&gt;&amp;lt;swarm_node_ip:2375&amp;gt; token://be1d6ac91667632d6635ee53b1f8caed
&lt;span class="c1"&gt;#之后在任意一台节点上运行swarm的管理节点&lt;/span&gt;
&amp;gt; docker run -d -p &lt;span class="m"&gt;2376&lt;/span&gt;:2375 swarm manage token://be1d6ac91667632d6635ee53b1f8caed
&lt;span class="c1"&gt;#执行docker的查询命令获得以下信息 &lt;/span&gt;
&amp;gt; docker -H tcp://&amp;lt;swarm_manage_ip:2376&amp;gt; info

Containers: &lt;span class="m"&gt;4&lt;/span&gt;
Images: &lt;span class="m"&gt;3&lt;/span&gt;
Role: primary
Strategy: spread
Filters: health, port, dependency, affinity, constraint
Nodes: &lt;span class="m"&gt;2&lt;/span&gt;
 dh1: &amp;lt;swarm_node1_ip:2375&amp;gt;
  └ Containers: &lt;span class="m"&gt;2&lt;/span&gt;
  └ Reserved CPUs: &lt;span class="m"&gt;0&lt;/span&gt; / &lt;span class="m"&gt;4&lt;/span&gt;
  └ Reserved Memory: &lt;span class="m"&gt;0&lt;/span&gt; B / &lt;span class="m"&gt;4&lt;/span&gt;.061 GiB
  └ Labels: &lt;span class="nv"&gt;executiondriver&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;native-0.2, &lt;span class="nv"&gt;kernelversion&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;.10.93-1.el6.elrepo.x86_64, &lt;span class="nv"&gt;operatingsystem&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&amp;lt;unknown&amp;gt;, &lt;span class="nv"&gt;storagedriver&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;devicemapper
 dh2: &amp;lt;swarm_node2_ip:2375&amp;gt;
  └ Containers: &lt;span class="m"&gt;2&lt;/span&gt;
  └ Reserved CPUs: &lt;span class="m"&gt;0&lt;/span&gt; / &lt;span class="m"&gt;4&lt;/span&gt;
  └ Reserved Memory: &lt;span class="m"&gt;0&lt;/span&gt; B / &lt;span class="m"&gt;4&lt;/span&gt;.061 GiB
  └ Labels: &lt;span class="nv"&gt;executiondriver&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;native-0.2, &lt;span class="nv"&gt;kernelversion&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;.10.93-1.el6.elrepo.x86_64, &lt;span class="nv"&gt;operatingsystem&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&amp;lt;unknown&amp;gt;, &lt;span class="nv"&gt;storagedriver&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;devicemapper
CPUs: &lt;span class="m"&gt;8&lt;/span&gt;
Total Memory: &lt;span class="m"&gt;8&lt;/span&gt;.121 GiB
Name: ca539e6846b8
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;更多信息请参见 &lt;a href="[https://docs.docker.com/v1.5/swarm/discovery/#using-the-hosted-discovery-service"&gt;Swarm官方文档&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;Consul发现模式配置&lt;/h4&gt;
&lt;p&gt;此文档为了方便统一管理使用docker方式安装Consul，其他方式请参见 &lt;a href="https://www.consul.io/docs/guides/index.html"&gt;Consul官方文档&lt;/a&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;#运行consul镜像，因为consul是关键服务而且很多地方可以用到网络使用host模式，直接端口绑定到主机&lt;/span&gt;
&lt;span class="c1"&gt;#-bootstrap表示初始化一个consul机群，ui参数可以启动consul自带的webui&lt;/span&gt;
&amp;gt; docker run --net&lt;span class="o"&gt;=&lt;/span&gt;host -P -d --name&lt;span class="o"&gt;=&lt;/span&gt;consul-1 progrium/consul -server -bootstrap -ui-dir /ui
&lt;span class="c1"&gt;#启动更多的consul节点，与zookeeper和etcd类似，此类服务都应该启动单数个节点便于仲裁&lt;/span&gt;
&amp;gt; docker run --net&lt;span class="o"&gt;=&lt;/span&gt;host -P -d --name&lt;span class="o"&gt;=&lt;/span&gt;consul-2 progrium/consul -server -join &amp;lt;first_node_ip&amp;gt;
&amp;gt; docker run --net&lt;span class="o"&gt;=&lt;/span&gt;host -P -d --name&lt;span class="o"&gt;=&lt;/span&gt;consul-3 progrium/consul -server -join &amp;lt;first_node_ip&amp;gt;
&lt;span class="c1"&gt;#使用consul启动swarm集群&lt;/span&gt;
&amp;gt; docker run -d swarm join --addr&lt;span class="o"&gt;=&lt;/span&gt;&amp;lt;swarm_node1_ip:2375&amp;gt; consul://&amp;lt;consul_node_ip:8500&amp;gt;/swarm
&lt;span class="c1"&gt;#启动第二个swarm节点，启动更多操作方式完全一样&lt;/span&gt;
&amp;gt; docker run -d swarm join --addr&lt;span class="o"&gt;=&lt;/span&gt;&amp;lt;swarm_node2_ip:2375&amp;gt; consul://&amp;lt;consul_node_ip:8500&amp;gt;/swarm
&lt;span class="c1"&gt;#启动管理节点&lt;/span&gt;
&amp;gt; docker run -d -p &lt;span class="m"&gt;2376&lt;/span&gt;:2375 swarm manage consul://&amp;lt;consul_node_ip:8500&amp;gt;/swarm
&amp;gt; docker -H tcp://&amp;lt;swarm_manage_ip:2376&amp;gt; info

Containers: &lt;span class="m"&gt;5&lt;/span&gt;
Images: &lt;span class="m"&gt;4&lt;/span&gt;
Role: primary
Strategy: spread
Filters: health, port, dependency, affinity, constraint
Nodes: &lt;span class="m"&gt;2&lt;/span&gt;
 dh1: &amp;lt;swarm_node1_ip:2375&amp;gt;
  └ Containers: &lt;span class="m"&gt;2&lt;/span&gt;
  └ Reserved CPUs: &lt;span class="m"&gt;0&lt;/span&gt; / &lt;span class="m"&gt;4&lt;/span&gt;
  └ Reserved Memory: &lt;span class="m"&gt;0&lt;/span&gt; B / &lt;span class="m"&gt;4&lt;/span&gt;.061 GiB
  └ Labels: &lt;span class="nv"&gt;executiondriver&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;native-0.2, &lt;span class="nv"&gt;kernelversion&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;.10.93-1.el6.elrepo.x86_64......
 dh2: &amp;lt;swarm_node2_ip:2375&amp;gt;
  └ Containers: &lt;span class="m"&gt;3&lt;/span&gt;
  └ Reserved CPUs: &lt;span class="m"&gt;0&lt;/span&gt; / &lt;span class="m"&gt;4&lt;/span&gt;
  └ Reserved Memory: &lt;span class="m"&gt;0&lt;/span&gt; B / &lt;span class="m"&gt;4&lt;/span&gt;.061 GiB
  └ Labels: &lt;span class="nv"&gt;executiondriver&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;native-0.2, &lt;span class="nv"&gt;kernelversion&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;.10.93-1.el6.elrepo.x86_64......
CPUs: &lt;span class="m"&gt;8&lt;/span&gt;
Total Memory: &lt;span class="m"&gt;8&lt;/span&gt;.121 GiB
Name: ca539e6846b8
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;顺带配置一个Shipyard webui来管理docker&lt;/h4&gt;
&lt;p&gt;Shipyard本身自带一套安装swarm的流程，但是我们前面已经做过很多准备工作了所以不需要更多工作
感兴趣的请参考 &lt;a href="http://shipyard-project.com/docs/deploy/automated/"&gt;Shipyard官方文档&lt;/a&gt;
我们这里只需要安装Shipyard依赖的rethinkdb和他的webui&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;#通过docker安装rethinkdb&lt;/span&gt;
docker run -ti -d --restart&lt;span class="o"&gt;=&lt;/span&gt;always --name shipyard-rethinkdb rethinkdb
&lt;span class="c1"&gt;#安装webui，需要link到rethinkdb，也就是说这两个服务需要安装到同一个docker node.&lt;/span&gt;
docker run -ti -d --restart&lt;span class="o"&gt;=&lt;/span&gt;always --name shipyard-controller --link shipyard-rethinkdb:rethinkdb &lt;span class="se"&gt;\&lt;/span&gt;
-p &lt;span class="m"&gt;8080&lt;/span&gt;:8080 shipyard/shipyard:latest server -d tcp://&amp;lt;swarm_manage_ip:2376&amp;gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h5&gt;到现在这个部署流程已经完成的差不多了，更详细的内容请查看各个组件的官方文档，在使用某个开源产品时建议第一件事就是详细阅读官方文档。&lt;/h5&gt;
&lt;h4&gt;后记：&lt;/h4&gt;
&lt;p&gt;由于目前官方docker对rhel6系列支持有限，官方只支持rhel6系列上安装1.7版本，所以一些高级功能不能使用，所以建议使用ubuntu 14.04以上或者rhel7系列发行版进行安装，我们目前使用的是ubuntu14.04，前面的教程除了docker守护进程配置文件为/etc/default/docker与centos6不同以及ubuntu14.04不用安装额外内核支持，其他操作均一摸一样。&lt;/p&gt;</content><category term="linux"></category><category term="docker"></category><category term="命令"></category></entry><entry><title>Docker常用命令</title><link href="http://puluto.github.io/dockerchang-yong-ming-ling.html" rel="alternate"></link><published>2015-11-26T18:52:00+08:00</published><updated>2015-11-26T18:52:00+08:00</updated><author><name>Puluto</name></author><id>tag:puluto.github.io,2015-11-26:/dockerchang-yong-ming-ling.html</id><summary type="html">&lt;h4&gt;容器安装操作(Linux内核需大于3.10)&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;#原始安装&lt;/span&gt;
curl -sSL https://get.docker.com/ &lt;span class="p"&gt;|&lt;/span&gt; sh
&lt;span class="c1"&gt;#国内安装，daocloud加速&lt;/span&gt;
curl -sSL https://get.daocloud.io/docker &lt;span class="p"&gt;|&lt;/span&gt; sh
&lt;span class="c1"&gt;#检查安装结果&lt;/span&gt;
sudo service docker status
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;安装docker的更多内容请参见: &lt;a href="http://docs.docker.com/engine/installation/"&gt;Docker官方安装文档&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;容器运行操作&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;#列出正在运行的容器&lt;/span&gt;
docker ps

&lt;span class="c1"&gt;#列出所有的容器&lt;/span&gt;
docker ps -a

&lt;span class="c1"&gt;#下载一个镜像到本地，并不运行&lt;/span&gt;
docker pull ubuntu

&lt;span class="c1"&gt;#运行一个容器，如果镜像不存在会自动进行pull&lt;/span&gt;
docker run -i -t ubuntu /bin/bash …&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;h4&gt;容器安装操作(Linux内核需大于3.10)&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;#原始安装&lt;/span&gt;
curl -sSL https://get.docker.com/ &lt;span class="p"&gt;|&lt;/span&gt; sh
&lt;span class="c1"&gt;#国内安装，daocloud加速&lt;/span&gt;
curl -sSL https://get.daocloud.io/docker &lt;span class="p"&gt;|&lt;/span&gt; sh
&lt;span class="c1"&gt;#检查安装结果&lt;/span&gt;
sudo service docker status
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;安装docker的更多内容请参见: &lt;a href="http://docs.docker.com/engine/installation/"&gt;Docker官方安装文档&lt;/a&gt;&lt;/p&gt;
&lt;h4&gt;容器运行操作&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;#列出正在运行的容器&lt;/span&gt;
docker ps

&lt;span class="c1"&gt;#列出所有的容器&lt;/span&gt;
docker ps -a

&lt;span class="c1"&gt;#下载一个镜像到本地，并不运行&lt;/span&gt;
docker pull ubuntu

&lt;span class="c1"&gt;#运行一个容器，如果镜像不存在会自动进行pull&lt;/span&gt;
docker run -i -t ubuntu /bin/bash

&lt;span class="c1"&gt;#运行容器并做端口转发至主机的3306，-e传入环境变量设置mysql的root密码&lt;/span&gt;
docker run --name test-mysql -e &lt;span class="nv"&gt;MYSQL_ROOT_PASSWORD&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;my-secret-pw -d -p &lt;span class="m"&gt;3306&lt;/span&gt;:3306 daocloud.io/library/mysql:latest
&lt;span class="c1"&gt;#运行一个tinyproxy代理&lt;/span&gt;
docker run -i -t -p :8888 dannydirect/tinyproxy:latest ANY

&lt;span class="c1"&gt;#以bash进入到运行中的容器&lt;/span&gt;
sudo docker &lt;span class="nb"&gt;exec&lt;/span&gt; -it &amp;lt;CONTAINER ID&amp;gt; /bin/bash

&lt;span class="c1"&gt;#删除所有容器&lt;/span&gt;
docker rm &lt;span class="sb"&gt;`&lt;/span&gt;docker ps -a -q&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;容器镜像操作&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;#列出所有镜像(images)&lt;/span&gt;
docker images

&lt;span class="c1"&gt;#通过Dockerfile构建一个映像文件，Dockerfile的每一行指令都会创建一个临时的Container&lt;/span&gt;
&lt;span class="c1"&gt;#–rm 选项是告诉Docker在构建完成后删除临时的Container，&lt;/span&gt;
docker build --rm&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nb"&gt;true&lt;/span&gt; -t mytest/tinyproxy .

&lt;span class="c1"&gt;#提交你的变更，并且把容器保存成镜像，命名为 mynewimage.&amp;lt;CONTAINER ID&amp;gt;为容器的ID.&lt;/span&gt;
docker commit &amp;lt;CONTAINER ID&amp;gt; mynewimage

&lt;span class="c1"&gt;#把 mynewimage 镜像保存成 tar 文件&lt;/span&gt;
docker save mynewimage &lt;span class="p"&gt;|&lt;/span&gt; bzip2 -9 -c &amp;gt; /home/mynewimage.tar.bz2

&lt;span class="c1"&gt;#加载 mynewimage 镜像&lt;/span&gt;
bzip2 -d -c &amp;lt; /home/mynewimage.tar.bz2 &lt;span class="p"&gt;|&lt;/span&gt; docker load

&lt;span class="c1"&gt;#删除镜像&lt;/span&gt;
docker rmi &lt;span class="o"&gt;[&lt;/span&gt;image-id&lt;span class="o"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;#导出正在运行的容器为Image&lt;/span&gt;
docker &lt;span class="nb"&gt;export&lt;/span&gt; &amp;lt;CONTAINER ID&amp;gt; &amp;gt; /home/export.tar

&lt;span class="c1"&gt;#导入Image镜像&lt;/span&gt;
cat /home/export.tar &lt;span class="p"&gt;|&lt;/span&gt; sudo docker import - mynewimage
&lt;/pre&gt;&lt;/div&gt;</content><category term="linux"></category><category term="docker"></category><category term="命令"></category></entry><entry><title>Linux下SCSI磁盘热插拔</title><link href="http://puluto.github.io/linuxxia-scsici-pan-re-cha-ba.html" rel="alternate"></link><published>2015-11-25T18:52:00+08:00</published><updated>2015-11-25T18:52:00+08:00</updated><author><name>Puluto</name></author><id>tag:puluto.github.io,2015-11-25:/linuxxia-scsici-pan-re-cha-ba.html</id><summary type="html">&lt;h3&gt;ESXi5中对Linux热添加磁盘时发现不生效，下文为临时解决方案&lt;/h3&gt;
&lt;p&gt;转载：&lt;a href="http://www.anrip.com/post/1295"&gt;技术写真 » Linux下SCSI磁盘热插拔&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;维护服务器时，有可能需要热插拔硬盘，但是Linux好像并不买单，不会自动检测磁盘的装卸，为此热插拔后，我们需要通知Linux服务磁盘状态。&lt;/p&gt;
&lt;h3&gt;添加磁盘，其中 2 0 1 0 分别对应 HOST CHAN DEV LUN&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;echo &amp;quot;scsi add-single-device 2 0 1 0&amp;quot; &amp;gt; /proc/scsi/scsi
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;查看磁盘&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;gt; cat /proc/scsi/scsi
Attached devices:
Host: scsi0 Channel: 00 Id: 00 Lun: 00
Vendor: NECVMWar Model …&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;h3&gt;ESXi5中对Linux热添加磁盘时发现不生效，下文为临时解决方案&lt;/h3&gt;
&lt;p&gt;转载：&lt;a href="http://www.anrip.com/post/1295"&gt;技术写真 » Linux下SCSI磁盘热插拔&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;维护服务器时，有可能需要热插拔硬盘，但是Linux好像并不买单，不会自动检测磁盘的装卸，为此热插拔后，我们需要通知Linux服务磁盘状态。&lt;/p&gt;
&lt;h3&gt;添加磁盘，其中 2 0 1 0 分别对应 HOST CHAN DEV LUN&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;echo &amp;quot;scsi add-single-device 2 0 1 0&amp;quot; &amp;gt; /proc/scsi/scsi
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;查看磁盘&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;gt; cat /proc/scsi/scsi
Attached devices:
Host: scsi0 Channel: 00 Id: 00 Lun: 00
Vendor: NECVMWar Model: VMware IDE CDR00 Rev: 1.00
Type:   CD-ROM                           ANSI  SCSI revision: 05
Host: scsi2 Channel: 00 Id: 00 Lun: 00
Vendor: VMware   Model: Virtual disk     Rev: 1.0
Type:   Direct-Access                    ANSI  SCSI revision: 02
Host: scsi2 Channel: 00 Id: 01 Lun: 00
Vendor: VMware   Model: Virtual disk     Rev: 1.0
Type:   Direct-Access                    ANSI  SCSI revision: 02
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;参数解析：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HOST 是硬盘所在SCSI控制器号(本例中，磁盘所在通道为2);&lt;/li&gt;
&lt;li&gt;CHAN 是硬盘所在SCSI通道的编号(一般单通道的就是0，多通道的要看是哪个通道了);&lt;/li&gt;
&lt;li&gt;DEV 是硬盘的SCSI ID号(可以通过具体插入的硬盘插槽来判断);&lt;/li&gt;
&lt;li&gt;LUN 是硬盘的lun号(默认情况都是0)&lt;/li&gt;
&lt;/ul&gt;</content><category term="linux"></category><category term="hotplug"></category></entry><entry><title>Celery简介</title><link href="http://puluto.github.io/celeryjian-jie.html" rel="alternate"></link><published>2015-01-03T10:20:00+08:00</published><updated>2015-01-03T10:20:00+08:00</updated><author><name>Puluto</name></author><id>tag:puluto.github.io,2015-01-03:/celeryjian-jie.html</id><summary type="html">&lt;p&gt;Celery(芹菜)是一个异步任务队列/基于分布式消息传递的作业队列。&lt;/p&gt;
&lt;p&gt;Celery用于生产系统每天处理数以百万计的任务。&lt;/p&gt;
&lt;p&gt;Celery是用Python编写的，但该协议可以在任何语言实现。它也可以与其他语言通过webhooks实现。&lt;/p&gt;
&lt;p&gt;由于Celery 3.0系列对以前的系列进行了大量重构优化，现在开始使用就没必要研究旧版本了，所以此介绍以3.0.24的文档为基础。&lt;/p&gt;
&lt;h3&gt;Celery的工作结构&lt;/h3&gt;
&lt;p&gt;在使用Celery的时候要明白它的大致结构，Celery的结构非常简单，大致分为3个部分：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;worker部分负责任务的处理，即工作线程，在我的理解中工作线程就是你写的python代码，当然还包括python调用系统工具功能&lt;/li&gt;
&lt;li&gt;broker部分负责任务消息的分发以及任务结果的存储，这部分任务主要由中间数据存储系统完成，比如消息队列服务器RabbitMQ、redis、
   Amazon SQS、MongoDB、IronMQ等或者关系型数据库，使用关系型数据库依赖sqlalchemy或者django的ORM&lt;/li&gt;
&lt;li&gt;Celery主类，进行任务最开始的指派与执行控制，他可以是单独的python脚本，也可以和其他程序结合，应用到django或者flask等
   web框架里面以及你能想到的任何应用&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Celery的安装&lt;/h3&gt;
&lt;p&gt;Celery只是一个python包，所以可以通过pip或者easy_install安装,除此之外还需要安装broker的系统，我使用的是redis，除了安装redis以外还需要安装celery-with-redis&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install celery
pip install celery-with-redis …&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;Celery(芹菜)是一个异步任务队列/基于分布式消息传递的作业队列。&lt;/p&gt;
&lt;p&gt;Celery用于生产系统每天处理数以百万计的任务。&lt;/p&gt;
&lt;p&gt;Celery是用Python编写的，但该协议可以在任何语言实现。它也可以与其他语言通过webhooks实现。&lt;/p&gt;
&lt;p&gt;由于Celery 3.0系列对以前的系列进行了大量重构优化，现在开始使用就没必要研究旧版本了，所以此介绍以3.0.24的文档为基础。&lt;/p&gt;
&lt;h3&gt;Celery的工作结构&lt;/h3&gt;
&lt;p&gt;在使用Celery的时候要明白它的大致结构，Celery的结构非常简单，大致分为3个部分：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;worker部分负责任务的处理，即工作线程，在我的理解中工作线程就是你写的python代码，当然还包括python调用系统工具功能&lt;/li&gt;
&lt;li&gt;broker部分负责任务消息的分发以及任务结果的存储，这部分任务主要由中间数据存储系统完成，比如消息队列服务器RabbitMQ、redis、
   Amazon SQS、MongoDB、IronMQ等或者关系型数据库，使用关系型数据库依赖sqlalchemy或者django的ORM&lt;/li&gt;
&lt;li&gt;Celery主类，进行任务最开始的指派与执行控制，他可以是单独的python脚本，也可以和其他程序结合，应用到django或者flask等
   web框架里面以及你能想到的任何应用&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Celery的安装&lt;/h3&gt;
&lt;p&gt;Celery只是一个python包，所以可以通过pip或者easy_install安装,除此之外还需要安装broker的系统，我使用的是redis，除了安装redis以外还需要安装celery-with-redis&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install celery
pip install celery-with-redis
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;使用其他类型的broker请参见官方文档：&lt;a href="http://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html#using-a-database"&gt;first-steps-with-celery.html#using-a-database&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Celery的初步使用&lt;/h3&gt;
&lt;p&gt;启动celery之前先架设好broker服务，安装好redis后以默认方式启动就可以了。
连接方式为：redis://localhost:6379/0&lt;/p&gt;
&lt;p&gt;接下来编写任务脚本tasks.py,这个脚本在worker部分和任务分发部分都需要用到：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;celery&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Celery&lt;/span&gt;

&lt;span class="n"&gt;celery&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Celery&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;tasks&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;broker&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;redis://localhost:6379/0&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nd"&gt;@celery.task&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;执行命令启动worker进行：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;#这个命令要在tasks.py文件目录运行，命令表示以worker模式启动一个名为tasks的APP&lt;/span&gt;
&lt;span class="c1"&gt;#worker的名称是test-worker1，一台服务器上可以启动多个worker，只要名称不同，&lt;/span&gt;
&lt;span class="c1"&gt;#启动好的worker会自动根据tasks.py的信息注册到broker服务中，等待分发任务。&lt;/span&gt;

celery -A tasks worker --loglevel&lt;span class="o"&gt;=&lt;/span&gt;info --hostname&lt;span class="o"&gt;=&lt;/span&gt;test-worker1
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;执行任务,使用delay()放，如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;tasks&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;add&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;delay&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;也可以使用apply_async()方法，把结果存储在类似broker的backend系统中，可以和broker在同一个服务中，
更改tasks.py中的实例化celery一行,加入backend参数：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;celery&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Celery&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;tasks&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;broker&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;redis://localhost:6379/0&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;backend&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;redis://localhost:6379/0&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;重新执行任务，使用apply_async把结果存储下来，在需要的时候调用get()进行获取，如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;tasks&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;add&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply_async&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Celery配置&lt;/h3&gt;
&lt;p&gt;Celery有很多全局变量，不配置的情况下取默认值，当我们需要配置的时候可以把所有的参数写到一个py文件中然后在
任务文件中进行加载，也可以直接用一个类写到任务文件中，还可以直接对celery类的conf对象直接进行update操作：&lt;/p&gt;
&lt;p&gt;方法1，直接加载py文件celeryconfig.py:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;BROKER_URL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;amqp://&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;CELERY_RESULT_BACKEND&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;amqp://&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;CELERY_TASK_SERIALIZER&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;json&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;CELERY_RESULT_SERIALIZER&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;json&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;CELERY_TIMEZONE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Europe/Oslo&amp;#39;&lt;/span&gt;
&lt;span class="n"&gt;CELERY_ENABLE_UTC&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;celery&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Celery&lt;/span&gt;

&lt;span class="n"&gt;celery&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Celery&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;celery&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;config_from_object&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;celeryconfig&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;方法2，直接对conf进行update：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;celery&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Celery&lt;/span&gt;

&lt;span class="n"&gt;celery&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Celery&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;celery&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
&lt;span class="n"&gt;CELERY_TASK_SERIALIZER&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;json&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="n"&gt;CELERY_RESULT_SERIALIZER&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;json&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="n"&gt;CELERY_TIMEZONE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Europe/Oslo&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="n"&gt;CELERY_ENABLE_UTC&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="ow"&gt;or&lt;/span&gt;

&lt;span class="n"&gt;celery&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CELERY_TASK_SERIALIZER&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;json&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;方法3，直接加载类或对象:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;celery&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Celery&lt;/span&gt;

&lt;span class="n"&gt;celery&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Celery&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Config&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;CELERY_ENABLE_UTC&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;
    &lt;span class="n"&gt;CELERY_TIMEZONE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;Europe/London&amp;#39;&lt;/span&gt;

&lt;span class="n"&gt;celery&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;config_from_object&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Config&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Celery任务分发控制&lt;/h3&gt;
&lt;p&gt;在celery里面任务分发控制叫task routing即任务路由&lt;/p&gt;
&lt;p&gt;celery的分发控制使用比较简单，但是高级功能比较复杂，我还不能完全理解，就介绍一下最基础的任务路由方法。&lt;/p&gt;
&lt;p&gt;在worker进程启动的时候可以使用参数-Q指定当前worker所能接受的队列消息：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;celery -A tasks.tasks worker --loglevel=info --hostname=testq-worker -Q &amp;#39;testq&amp;#39;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;然后在任务分发的过程中，调用apply_async或者delay方法中指定queue参数，当queue与worker的-Q相匹配时任务
就可以被分发到相应的worker进程中：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;tasks&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;add&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply_async&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;queue&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;testq&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;更高级的使用方法请大家研究官网的文档：
&lt;a href="http://docs.celeryproject.org/en/latest/userguide/routing.html"&gt;docs-routing&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Celery的管理&lt;/h3&gt;
&lt;p&gt;celery的管理有几种方式，比较直观的有一个叫flower的webui，可以提供任务查询，worker的生命管理以及路由管理，可以在界面上
进行实时的路由key添加（就是在worker启动时-Q参数指定的值）&lt;/p&gt;
&lt;p&gt;使用方式为：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;pip install flower
celery flower --port&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;5555&lt;/span&gt; --broker&lt;span class="o"&gt;=&lt;/span&gt;redis://localhost:6379/0
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;访问&lt;a href="http://flower-server:5555"&gt;http://flower-server:5555&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;还有一种对任务进行实时监控的方式为celery本身提供的events的功能，启动方式为：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;celery events --broker&lt;span class="o"&gt;=&lt;/span&gt;redis://localhost:6379/0
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;结束语&lt;/h2&gt;
&lt;p&gt;celery还有很多功能没来得及研究，我准备把celery应用于服务器管理中一些任务的执行，来代替linux的crontab和一些手工操作，提升更强的灵活性以及更加直观&lt;/p&gt;</content><category term="python"></category><category term="celery"></category></entry><entry><title>Saltstack入门</title><link href="http://puluto.github.io/saltstackru-men.html" rel="alternate"></link><published>2015-01-03T10:20:00+08:00</published><updated>2015-01-03T10:20:00+08:00</updated><author><name>Puluto</name></author><id>tag:puluto.github.io,2015-01-03:/saltstackru-men.html</id><summary type="html">&lt;div class="section" id="id1"&gt;
&lt;h2&gt;什么是Saltstack？&lt;/h2&gt;
&lt;div class="section" id="apache2"&gt;
&lt;h3&gt;以Apache2 协议开源的管理服务器基础设施以及服务的轻量级工具（所谓轻量级是说工具结构简单、并不是说功能简单）&lt;/h3&gt;
&lt;p&gt;可以远程执行命令管理，也可以进行服务器相关的状态管理，通常我们认为salt是fedora func与 puppet 的结合体&lt;/p&gt;
&lt;p&gt;使用Python编写，通过证书加密保证通讯安全，使用0MQ作为通讯承载方式具有很高的性能以及灵活性&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h3&gt;标准化模块实现各种功能，没有自己开发不通用的技术&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Python 2.6 &amp;gt;== 2.6 &amp;lt;3.0&lt;/li&gt;
&lt;li&gt;ZeroMQ &amp;gt;== 2.1.9&lt;/li&gt;
&lt;li&gt;pyzmq &amp;gt;== 2.1.9 -------- ZeroMQ Python bindings&lt;/li&gt;
&lt;li&gt;PyCrypto -------- The Python cryptography toolkit&lt;/li&gt;
&lt;li&gt;msgpack--------python -------- High--------performance message interchange format&lt;/li&gt;
&lt;li&gt;YAML -------- Python YAML bindings&lt;/li&gt;
&lt;li&gt;Jinja2 -------- parsing …&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;</summary><content type="html">&lt;div class="section" id="id1"&gt;
&lt;h2&gt;什么是Saltstack？&lt;/h2&gt;
&lt;div class="section" id="apache2"&gt;
&lt;h3&gt;以Apache2 协议开源的管理服务器基础设施以及服务的轻量级工具（所谓轻量级是说工具结构简单、并不是说功能简单）&lt;/h3&gt;
&lt;p&gt;可以远程执行命令管理，也可以进行服务器相关的状态管理，通常我们认为salt是fedora func与 puppet 的结合体&lt;/p&gt;
&lt;p&gt;使用Python编写，通过证书加密保证通讯安全，使用0MQ作为通讯承载方式具有很高的性能以及灵活性&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h3&gt;标准化模块实现各种功能，没有自己开发不通用的技术&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Python 2.6 &amp;gt;== 2.6 &amp;lt;3.0&lt;/li&gt;
&lt;li&gt;ZeroMQ &amp;gt;== 2.1.9&lt;/li&gt;
&lt;li&gt;pyzmq &amp;gt;== 2.1.9 -------- ZeroMQ Python bindings&lt;/li&gt;
&lt;li&gt;PyCrypto -------- The Python cryptography toolkit&lt;/li&gt;
&lt;li&gt;msgpack--------python -------- High--------performance message interchange format&lt;/li&gt;
&lt;li&gt;YAML -------- Python YAML bindings&lt;/li&gt;
&lt;li&gt;Jinja2 -------- parsing Salt States (configurable in the master settings)&lt;/li&gt;
&lt;li&gt;Python--------m2crypto -------- M2Crypto Python bindings&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="id3"&gt;
&lt;h3&gt;高效率：&lt;/h3&gt;
&lt;blockquote&gt;
Salt的C/S核心采用0MQ消息队列以及msgpack进行通信，网络开销非常小并且可以并行异步执行任务，所以单台普通配置master可以支撑
几百台甚至上千台的minion管理，并且速度能得到保障。&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="section" id="id4"&gt;
&lt;h3&gt;可扩展：&lt;/h3&gt;
&lt;blockquote&gt;
Salt的部署扩展非常灵活，自带分布式部署方式，通过salt--------syndic服务进行分布式管理以及0.16版本新增的多master结构，
功能的扩展上可以很容易的编写自定义的模块进行拓展，并且扩展模块很容易利用现有的模块进行功能的强化。&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div class="section" id="id5"&gt;
&lt;h3&gt;灵活性：&lt;/h3&gt;
&lt;blockquote&gt;
Salt在使用方面对目标端的匹配可以使用多种方式，可以通过指定分组、linux通配符、正则表达式、grains模块信息进行目标端的过滤，
salt本身提供了丰富的返回信息输出方式，除了可以终端输出还可以指定返回信息输出到各种数据存储服务当中，比如mysql、redis、
mangodb等并且可以很方便的根据自己的需要对returnner模块进行扩展满足自己的特殊需求。&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="id6"&gt;
&lt;h2&gt;安装Saltstack&lt;/h2&gt;
&lt;div class="section" id="id7"&gt;
&lt;h3&gt;支持的系统：&lt;/h3&gt;
&lt;p&gt;已经在常见的系统打包好了，可以直接使用包管理工具安装使用
* Fedora
* RedHat Enterprise Linux / Centos (EPEL 5,&amp;nbsp;EPEL 6)
* Ubuntu (PPA)
* Arch (AUR)
* FreeBSD
* Gentoo
* Debian&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id8"&gt;
&lt;h3&gt;如果特殊环境不方便直接使用包管理工具可以源码安装：&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Python 2.6 &amp;gt;== 2.6 &amp;lt;3.0&lt;/li&gt;
&lt;li&gt;ZeroMQ &amp;gt;== 2.1.9&lt;/li&gt;
&lt;li&gt;pyzmq &amp;gt;== 2.1.9 -------- ZeroMQ Python bindings&lt;/li&gt;
&lt;li&gt;PyCrypto -------- The Python cryptography toolkit&lt;/li&gt;
&lt;li&gt;msgpack--------python – 高性能消息序列化工具&lt;/li&gt;
&lt;li&gt;YAML -------- 一种通用的结构化数据格式、GAE的配置就是使用这个&lt;/li&gt;
&lt;li&gt;MarkupSafe – jinja2依赖&lt;/li&gt;
&lt;li&gt;Jinja2 -------- 默认模版模块，如需要支持mako模版也需要安装&lt;/li&gt;
&lt;li&gt;Python--------m2crypto -------- M2Crypto Python bindings&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Salt带来的惊喜是他支持Windows的操作，当然由于Windows本身的原因目前功能有限，不过正在完善中。&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="master"&gt;
&lt;h3&gt;Master:&lt;/h3&gt;
&lt;p&gt;安装完成以后修改/etc/salt/master配置文件后执行:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/etc/init.d/salt--------master start
&lt;/pre&gt;
&lt;p&gt;Tips: &lt;em&gt;默认可以不用进行任何配置便可以启动&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="minion"&gt;
&lt;h3&gt;Minion:&lt;/h3&gt;
&lt;p&gt;安装完成以后修改/etc/salt/minion配置文件里面的Master：行指定master服务器的位置:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/etc/init.d/salt--------minion start
&lt;/pre&gt;
&lt;p&gt;配置文件里面所有的项冒号后面需要跟一个空格，这是yaml文件的语法,例如:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Master: x.x.x.x
&lt;/pre&gt;
&lt;p&gt;如果是编译安装在/etc/目录和init.d目录是没有相关文件的，需要进入源码目录执行:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
cp --------a conf /etc/salt
cp pkg/salt--------master.service /etc/init.d/salt--------master
cp pkg/salt--------minion.service /etc/init.d/salt--------minion
&lt;/pre&gt;
&lt;p&gt;安装启动完成后在Master机器上执行:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
salt--------key –L             #可以列出所有minion发送到Master的认证key信息
salt--------key –A             #可以通过所有minion的认证
salt--------key –a  minion--------id  #通过指定id的minion认证，minion--------id默认是机器名，
                        #也可以通过minion的配置文件里id一项进行指定，不同minion的id不能相同
&lt;/pre&gt;
&lt;p&gt;认证完成后就可以执行salt命令进行管理了，测试:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
salt '*' test.ping
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="salt"&gt;
&lt;h2&gt;Salt的使用&lt;/h2&gt;
&lt;p&gt;salt包含多个子系统，其中比较主要的有:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;modules -------- salt中最基础的系统，主要功能为批量发送指令控制服务器，使用模块封装了很多平时常用的功能&lt;/li&gt;
&lt;li&gt;states -------- 与puppet的配置管理类似的功能，优点是简单灵活容易扩展，成熟度正在向puppet靠拢&lt;/li&gt;
&lt;li&gt;runner -------- 用于在服务端定义一些复杂的功能模块分发到minion执行，用到的机会比较少&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;常用的与主要子系统配合的辅助子系统:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;target -------- 主要工作是匹配过滤minion，在对服务器执行主要功能的时候对客户端进行筛选精确匹配&lt;/li&gt;
&lt;li&gt;grains -------- 存储minion端系统相关和部分硬件信息，里面的信息可以用于资产管理，因为默认会统计配置信息以及硬件序列号&lt;/li&gt;
&lt;li&gt;render -------- 用于salt中模版文件的渲染，各个系统的配置文件均支持模版语言，默认支持jinja2，可以扩展支持mako等模版引擎&lt;/li&gt;
&lt;li&gt;pillar -------- 用于对minion端敏感信息的分发以及作为一个统一的变量系统，里面设定的变量或者内容只对其匹配到的客户端进行精确分发&lt;/li&gt;
&lt;li&gt;schedule -------- 用于定时在Master或者minion端执行特定的任务的模块，相当于Linux系统的crontab，这个更便于管理&lt;/li&gt;
&lt;li&gt;returner -------- 用于特定方式返回salt任务执行后的结果，可以将结果输出到不同的存储端，比如mysql、redis、syslog、local、mangodb等&lt;/li&gt;
&lt;li&gt;acl system --------&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="modules"&gt;
&lt;h3&gt;modules的使用&lt;/h3&gt;
&lt;p&gt;modules服务是salt远程执行命令的服务，是salt中最基础的功能，salt很多扩展功能均利用modules
modules的模块中还有专门针对虚拟化和云计算的模块，包括非常详细的virt模块和虚拟网卡模块以及ec2的模块：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;以下为modules服务的一些实例&lt;/strong&gt;
安装完成后测试所有通过认证的服务器，并且id为test1机器安装vim:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
salt '*' test.ping
salt 'test1' pkg.install vim
&lt;/pre&gt;
&lt;p&gt;Tips: &lt;em&gt;pkg模块的参数中，包名是依赖系统所确定的包名，不同发行版可能会出现不同，比如apache在redhat系列叫httpd，debian中叫apache2&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;modules命令使用格式:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
salt 'target' modules.function arg1 arg2 ... args_key==value
&lt;/pre&gt;
&lt;p&gt;salt的modules已经自带了很多常用模块，可以从官方文档看到，如果没有相应的模块也可以使用cmd.run模块通过shell实现简单的功能:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
salt '*' cmd.run 'uptime'
salt terminal2 cmd.run &amp;quot;cat /etc/hosts&amp;quot;
&amp;gt;
terminal2:
  #         Do not remove the following line, or various programs
  #         that require network functionality will fail.
  127.0.0.1         localhost
  ...
&lt;/pre&gt;
&lt;p&gt;modules服务中有很多模块，如果对模块的用法以及函数难以记录可以使用sys.argspec模块对其他模块的用法进行查询:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
salt 'terminal2' sys.argspec saltutil
&amp;gt;
terminal2:
--------------------------------------------------------------------------------
  saltutil.find_job:
    --------------------------------------------------------------------------------
    args:
        -------- jid
    defaults:
        None
    kwargs:
        None
    varargs:
        None
  saltutil.is_running:
    ...
  ...
&lt;/pre&gt;
&lt;p&gt;Tips: &lt;em&gt;此命令可以输出saltutil模块的所有函数以及函数的参数&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;如果需要对某个具体函数进行查询可以和上面的用法相同:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
salt 'terminal2' sys.argspec saltutil.is_running
&amp;gt;
terminal2:
--------------------------------------------------------------------------------
  saltutil.is_running:
    --------------------------------------------------------------------------------
    args:
        -------- fun
    defaults:
        None
    kwargs:
        None
    varargs:
        None
&lt;/pre&gt;
&lt;p&gt;也可以使用sys.doc命令查询模块的相关文档:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
salt 'terminal2' sys.doc saltutil.is_running
&amp;gt;
saltutil.is_running:

  If the named function is running return the data associated with it/them.
  The argument can be a glob

  CLI Example:

    salt '*' saltutil.is_running state.highstate
&lt;/pre&gt;
&lt;p&gt;Tips: &lt;em&gt;直接运行salt 'terminal2' sys.doc可以输出当前可用的所有模块信息&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="state"&gt;
&lt;h3&gt;state服务的使用&lt;/h3&gt;
&lt;p&gt;配置state功能的描述文件根目录，state描述文件使用yaml格式以.sls为后缀，在指定的根目录以top.sls为入口文件进行解析执行:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
vim  /etc/salt/master

file_roots:
base:
  -------- /data/srv/salt/
&lt;/pre&gt;
&lt;p&gt;修改好配置文件，重启Master服务:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
cd /data/srv/salt/

vim top.sls      #输入以下内容
base:            #环境名称，file_roots可以指定多个环境，不同环境不同目录
  '*':           #需要匹配的客户端，*号代表所有minion
    -------- test       #test代表匹配到的客户端需要执行的任务或者模块
&lt;/pre&gt;
&lt;p&gt;建立test任务，任务可以是一个sls文件，也可以是目录:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
vim test.sls     #如果test任务是一个目录，那么如果直接调用test任务需要把任务内容写到test目录下的init.sls文件中
                 #在test目录中非init.sls文件名的调用需要的格式为test.task，或者在init文件中include另外的文件内容
zabbix_agentd:
  pkg:
    -------- installed

/etc/zabbix/zabbox_agentd.conf:
  file:
    -------- managed
    -------- source: salt://file/zabbix_agentd.conf
    -------- mode: 644
    -------- user: root

zabbix_agentd_service:
  service.running:
    -------- name: zabbix_agentd
    -------- enable: True
    -------- enable: reload
    -------- require:
      -------- pkg: zabbix_agentd
    -------- watch:
      -------- file: /etc/zabbix/zabbox_agentd.conf
&lt;/pre&gt;
&lt;p&gt;书写state系统的sls文件的标准为:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
task_id:                         #定义一条命令的id，id在整个系统中是唯一的，不能重复
  module:                        #state支持的模块名称
    -------- function                   #模块的函数名称，你需要执行的具体任务
    -------- args_key: args_value       #模块需要指定的一些参数
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="target"&gt;
&lt;h3&gt;target的使用&lt;/h3&gt;
&lt;p&gt;target是用于在执行modules或者state以及后面要讲到的pillar系统时匹配目标机器的功能
对于目标的匹配target支持多种模式:&lt;/p&gt;
&lt;p&gt;Linux的shell通配符匹配，默认情况下target均使用此类模式:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
salt 'web*' test.ping                #匹配所有经过认证的minion客户端
salt 'web[1--------9x--------z]' test.ping         #可以匹配到web1--------9以及webx、weby、webz
salt 'web?' test.ping                #匹配web后面只有一个字符的客户端
&lt;/pre&gt;
&lt;p&gt;正则表达式匹配,使用正则匹配需要命令行指定`--------E`参数:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
salt --------E 'web1--------(prd|dev)' test.ping
&lt;/pre&gt;
&lt;p&gt;如果是在state的top.sls中使用正则匹配，需要在匹配表达式里指定`match`参数的值为pcre:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
base:
  'web1--------(prd|dev)':
  -------- match: pcre
  -------- webserver
&lt;/pre&gt;
&lt;p&gt;在执行对多个minion的操作时，客户端数量较小比较难使用通配符或者正则的情况下可以使用`--------L`参数手动输入minion列表:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
salt --------L 'web1,web2,web3' test.ping
&lt;/pre&gt;
&lt;p&gt;通过Grains系统的值进行匹配，指定参数`--------G`:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
salt --------G 'os:CentOS' test.ping
salt --------G 'cpuarch:x86_64' test.ping
&lt;/pre&gt;
&lt;p&gt;使用`--------N` 参数可以使用预先设定的分组进行minion的匹配:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
salt --------N group1 test.ping
&lt;/pre&gt;
&lt;p&gt;设定group的方式为，修改Master的配置文件添加nodegroups段，并且进行分组的时候可以利用其他几类匹配方式帮助分组:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
nodegroups:
  group1: 'L&amp;#64;foo.domain.com,bar.domain.com,baz.domain.com or bl*.domain.com'
  group2: 'G&amp;#64;os:Debian and foo.domain.com'
&lt;/pre&gt;
&lt;p&gt;和上面分组一样，执行命令或者state的时候同样可以进行混合匹配,命令需要指定`--------C`参数表示混合匹配:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
salt --------C 'webserv* and G&amp;#64;os:Debian or E&amp;#64;web--------dc1--------srv.*' test.ping
&lt;/pre&gt;
&lt;p&gt;在state和pillar中使用的时候需要指定match参数的值为compound:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
base:
  'webserv* and G&amp;#64;os:Debian or E&amp;#64;web--------dc1--------srv.*':
  -------- match: compound
  -------- webserver
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="grains"&gt;
&lt;h3&gt;grains服务介绍&lt;/h3&gt;
&lt;p&gt;Grains服务是salt里面记录一些系统重要信息的模块，并且这些信息可以方便的查看使用和自定义&lt;/p&gt;
&lt;p&gt;查看系统里面所有的Grains项目:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;
salt 'terminal2' grains.ls

  terminal2:
  -------- biosreleasedate
  -------- biosversion
  -------- cpu_flags
  -------- cpu_model
  -------- cpuarch
  -------- defaultencoding
  -------- defaultlanguage
  -------- domain
  -------- fqdn
  -------- gpus
  -------- host
  -------- id
  -------- ip_interfaces
  -------- ipv4
  -------- kernel
  ...
&lt;/pre&gt;
&lt;p&gt;查看系统Grains所有项目以及对应的值:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;
salt 'terminal2' grains.items

terminal2:
  biosreleasedate: 09/08/2010
  biosversion: 1.4.8
  cpu_flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse
           sse2 ss ht tm syscall nx pdpe1gb rdtscp lm constant_tsc ida nonstop_tsc pni monitor ds_cpl vmx smx est
           tm2 cx16 xtpr popcnt lahf_lm
  cpu_model: Intel(R) Xeon(R) CPU           E5620  &amp;#64; 2.40GHz
  cpuarch: x86_64
  defaultencoding: UTF8
  defaultlanguage: zh_CN
  domain:
  fqdn: terminal2
  gpus:
  host: terminal2
  id: terminal2
  ip_interfaces: {'sit0': [], 'lo': ['127.0.0.1'], 'eth1': ['10.11.10.21'], 'eth0': ['121.10.118.21',
  '112.91.18.21']}
  ipv4:
    127.0.0.1
    10.11.10.21
    121.10.118.21
    112.91.18.21
  kernel: Linux
  kernelrelease: 2.6.18--------164.el5
&lt;/pre&gt;
&lt;p&gt;查看某一个Grains项目的值:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;
salt 'terminal2' grains.item os

terminal2:
  os: CentOS
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="render"&gt;
&lt;h3&gt;render系统的介绍&lt;/h3&gt;
&lt;p&gt;在Salt中模版系统是一个很重要的功能，可以帮助我们尽可能的少写代码以及增强salt应用的灵活性，render系统默认使用jinja2和yaml，可以
通过扩展或者设置支持json、mako、py、pydsl、wempy、stateconf。&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;在render系统中包括两类文件表述的支持：&lt;/dt&gt;
&lt;dd&gt;&lt;ul class="first last simple"&gt;
&lt;li&gt;一类是传统意义的模版，即jinja2、mako，这些模版系统包括逻辑处理支持以及一些简单的数据处理语句&lt;/li&gt;
&lt;li&gt;另一类其实是一种数据格式，不支持逻辑语句，比如yaml、json、pydsl这些就属于数据格式&lt;/li&gt;
&lt;/ul&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;jinja2在state服务中的使用:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
zabbix_agentd:
   pkg:
     -------- installed

/etc/zabbix/zabbox_agentd.conf:
   file:
     -------- managed
     #通过Grains里面的os信息判断系统类型，分发不同的文件，也可以在任何地方使用jinja2模版的其他功能
     {% if grains['os'] ==== 'CentOS' %}
     -------- source: salt://file/zabbix_agentd.conf
     {% else %}
     -------- source: salt://file/zabbix_agentd_other.conf
     {% endif %}
     -------- mode: 644
     -------- template: jinja
     -------- user: root
&lt;/pre&gt;
&lt;p&gt;通过设定上面statefile的template参数为jinja，也可以使state管理的文件能使用jinja2作为模版进行渲染:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
vim /srv/salt/prd/source/conf/zabbix_agentd.conf

  ### Option: Server
  #       List of comma delimited IP addresses (or hostnames) of Zabbix servers.
  #       Incoming connections will be accepted only from the hosts listed here.
  #       No spaces allowed.
  #       If IPv6 support is enabled then '127.0.0.1', '::127.0.0.1', '::ffff:127.0.0.1' are treated equally.
  #
  # Mandatory: no
  # Default:
  # Server==
  {% if grains['os'] ==== 'CentOS' %}
  Server==10.11.10.21
  {% else %}
  Server==10.12.10.130
  {% endif %}
  ...
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;我们可以通过自定义grains来为模版加入很大的灵活性，并且模版系统还可以引用pillars系统的元素，这个后面会讲到&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="pillar"&gt;
&lt;h3&gt;pillar服务的使用&lt;/h3&gt;
&lt;p&gt;Pillar服务是salt用于将一些全局数据分发到minion的一个接口，pillar以salt state类似的方式组织数据，存放与pillar的数据只会分发
到定义里所匹配到的minion客户端，所以可以用于敏感信息的分发，比如用户名密码之类的安全数据。
但目前我们一般将其作为一个全局的变量系统使用，pillar的数据可以供state和render服务所使用。&lt;/p&gt;
&lt;p&gt;在Master的配置文件里设定pillar服务:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
vim /etc/salt/master

pillars_roots:
  base:
    -------- /srv/pillar/
&lt;/pre&gt;
&lt;p&gt;与state系统一样，使用pillar的方式是先定义top.sls:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
vim /srv/pillar/top.sls

base:                 #默认环境
  '*':                #匹配的目标
    -------- system          #引用定义的system文件或者模块
    -------- software        #引用定义的software文件或者模块
&lt;/pre&gt;
&lt;p&gt;定义了top.sls以后，需要top里面所引用的文件或者模块，这里以文件为例:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#默认pillar的数据使用K、V方式存储，V可以是字符或者列表，并且下面例子也使用了render服务

vim /srv/pillar/system.sls

{% if grains['os_family'] ==== 'Suse' %}
vim: 'vim'
vimrc: 'vimrc_suse'
nrpe_init: 'init--------script.suse.in'
{% elif grains['os_family'] ==== 'RedHat' %}
vim: 'vim--------enhanced'
vimrc: 'vimrc_redhat'
nrpe_init: 'init--------script.in'
{% elif grains['os_family'] ==== 'Debian' %}
vim: 'vim'
vimrc: 'vimrc_debian'
nrpe_init: 'init--------script.debian.in'
{% endif %}
&lt;/pre&gt;
&lt;p&gt;定义完成后查看pillar的数据:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
&amp;gt;
salt 'terminal2' pillar.data

terminal2:
  build_root:
      /usr/local
  nrpe_init:
      init--------script.in
  salt_src:
      salt://source
  salt_tmp:
      /tmp/salt
  sys:
      --------------------------------------------------------------------------------
      profile:
          profile_redhat
  vim:
      vim--------enhanced
  vimrc:
      vimrc_redhat
  ....
&lt;/pre&gt;
&lt;p&gt;在state中调用pillar的数据:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#在state中设定安装vim并且同步配置文件，因为不同系统vim包名不同，所以我们把这些差异都放到前面的pillar里面
#这样在编辑statefile的时候就只需要调用变量，他会根据不同的系统给出不同的包名
#在state所管理的文件里面也可以引用pillar的数据，所以我们可以把一些软件的特定配置写到pillar服务

vim /srv/salt/prd/states/vim/init.sls

vimrc:
 pkg.installed:
   -------- name: {{ pillar['vim'] }}
 file.managed:
   -------- name: /etc/vimrc
   -------- source: {{ pillar['salt_src'] }}/conf/{{ pillar['vimrc'] }}
   -------- mode: 644
   -------- require:
     -------- pkg: {{ pillar['vim'] }}
&lt;/pre&gt;
&lt;p&gt;在pillar中的数据也可以划分层级逐层调用,下面设定一个多级的pillar定义文件:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
vim /srv/pillar/system/init.sls

sys:
{% if &amp;quot;RedHat&amp;quot; ==== grains['os_family'] %}
  profile: profile_redhat
{% elif &amp;quot;Suse&amp;quot; ==== grains['os_family'] %}
  profile: profile_suse
{% elif &amp;quot;Debian&amp;quot; ==== grains['os_family'] %}
  profile: profile_debian
{% endif %}
&lt;/pre&gt;
&lt;p&gt;在使用上面定义的数据时就需要根据定义时的层级进行访问，可以方便的为数据分类:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#其中profile的文件名就经过了两层，我们可以在定义软件的配置时把第一层命名为软件名，第二层定义软件的配置可以方便管理
vim /srv/salt/prd/states/users/init.sls

/etc/profile:
  file:
    -------- managed
    -------- source: {{ pillar['salt_src'] }}/conf/{{ pillar['sys']['profile'] }}
    -------- mode: 644
    -------- user: root
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="schedule"&gt;
&lt;h3&gt;Schedule系统的使用&lt;/h3&gt;
&lt;p&gt;schedule系统用于指定时间循环执行Master或者minion上的任务，当我们写好statefile需要保持minion处于指定状态的时候，就可以在
指定时间间隔执行state.highstate模块来保证state的同步。&lt;/p&gt;
&lt;p&gt;schedule系统的启用方式:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#编辑minion的配置文件加入以下配置，重启salt--------minion端
schedule:                         #schedule系统的标识，不能更改
  highstate:                      #需要执行的任务ID，可以任意更改不能重复，建议使用函数的名称表示
    function: state.highstate     #function后面跟 `模块.函数名`表示需要执行的任务
    minutes: 60                   #表示每60分钟执行一次
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;时间周期还可以指定minutes和hours，指定时间的所有项的总时间加在一起表示一个周期&lt;/em&gt;
&lt;em&gt;根据以上格式，schedule里面可以加入任何想执行的模块，这些模块就是salt的modules系统里面包含的模块，也可以进行自定义模块&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;schedule系统可以和returner结合将任务执行结果输出到指定位置:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#表示每60秒统计一次系统的uptime，并将执行结果存入mysql数据库
schedule:
  uptime:
    function: status.uptime
    seconds: 60
    returner: mysql
&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;returner系统的详细介绍将在后续完善，目前还没有使用returner系统&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;本教程为基础教程，由于我比较糟糕的表述能力，请各位看官见谅&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;更多教程请参见&lt;/strong&gt;
__ &lt;a class="reference external" href="http://saltstack.cn"&gt;http://saltstack.cn&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="python"></category><category term="saltstack"></category></entry></feed>