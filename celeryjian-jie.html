
<!DOCTYPE html>
<html lang="zh">
<head>
  <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,400italic' rel='stylesheet' type='text/css'>

    <link rel="stylesheet" type="text/css" href="http://puluto.github.io/theme/stylesheet/style.min.css">

  <link rel="stylesheet" type="text/css" href="http://puluto.github.io/theme/pygments/monokai.min.css">
  <link rel="stylesheet" type="text/css" href="http://puluto.github.io/theme/font-awesome/css/font-awesome.min.css">

    <link href="http://puluto.github.io/static/custom.css" rel="stylesheet">

    <link href="http://puluto.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Thinking Atom">



  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="robots" content="" />


<meta name="author" content="Puluto" />
<meta name="description" content="Celery(芹菜)是一个异步任务队列/基于分布式消息传递的作业队列。 Celery用于生产系统每天处理数以百万计的任务。 Celery是用Python编写的，但该协议可以在任何语言实现。它也可以与其他语言通过webhooks实现。 由于Celery 3.0系列对以前的系列进行了大量重构优化，现在开始使用就没必要研究旧版本了，所以此介绍以3.0.24的文档为基础。 Celery的工作结构 在使用Celery的时候要明白它的大致结构，Celery的结构非常简单，大致分为3个部分： worker部分负责任务的处理，即工作线程，在我的理解中工作线程就是你写的python代码，当然还包括python调用系统工具功能 broker部分负责任务消息的分发以及任务结果的存储，这部分任务主要由中间数据存储系统完成，比如消息队列服务器RabbitMQ、redis、 Amazon SQS、MongoDB、IronMQ等或者关系型数据库，使用关系型数据库依赖sqlalchemy或者django的ORM Celery主类，进行任务最开始的指派与执行控制，他可以是单独的python脚本，也可以和其他程序结合，应用到django或者flask等 web框架里面以及你能想到的任何应用 Celery的安装 Celery只是一个python包，所以可以通过pip或者easy_install安装,除此之外还需要安装broker的系统，我使用的是redis，除了安装redis以外还需要安装celery-with-redis pip install celery pip install celery-with-redis …" />
<meta name="keywords" content="python, celery">
<meta property="og:site_name" content="Thinking"/>
<meta property="og:title" content="Celery简介"/>
<meta property="og:description" content="Celery(芹菜)是一个异步任务队列/基于分布式消息传递的作业队列。 Celery用于生产系统每天处理数以百万计的任务。 Celery是用Python编写的，但该协议可以在任何语言实现。它也可以与其他语言通过webhooks实现。 由于Celery 3.0系列对以前的系列进行了大量重构优化，现在开始使用就没必要研究旧版本了，所以此介绍以3.0.24的文档为基础。 Celery的工作结构 在使用Celery的时候要明白它的大致结构，Celery的结构非常简单，大致分为3个部分： worker部分负责任务的处理，即工作线程，在我的理解中工作线程就是你写的python代码，当然还包括python调用系统工具功能 broker部分负责任务消息的分发以及任务结果的存储，这部分任务主要由中间数据存储系统完成，比如消息队列服务器RabbitMQ、redis、 Amazon SQS、MongoDB、IronMQ等或者关系型数据库，使用关系型数据库依赖sqlalchemy或者django的ORM Celery主类，进行任务最开始的指派与执行控制，他可以是单独的python脚本，也可以和其他程序结合，应用到django或者flask等 web框架里面以及你能想到的任何应用 Celery的安装 Celery只是一个python包，所以可以通过pip或者easy_install安装,除此之外还需要安装broker的系统，我使用的是redis，除了安装redis以外还需要安装celery-with-redis pip install celery pip install celery-with-redis …"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="http://puluto.github.io/celeryjian-jie.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2015-01-03 10:20:00+08:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="http://puluto.github.io/author/puluto.html">
<meta property="article:section" content="任务调度"/>
<meta property="article:tag" content="python"/>
<meta property="article:tag" content="celery"/>
<meta property="og:image" content="">

  <title>Thinking &ndash; Celery简介</title>

</head>
<body>
  <aside>
    <div>
      <a href="http://puluto.github.io">
        <img src="http://puluto.github.io/theme/img/profile.png" alt="Puluto" title="Puluto">
      </a>
      <h1><a href="http://puluto.github.io">Puluto</a></h1>

<p>更新很慢的博客，关于自己研究的一些东西</p>
      <nav>
        <ul class="list">
          <li><a href="http://puluto.github.io/pages/about-me.html#about-me">About me</a></li>

          <li><a href="http://getpelican.com/" target="_blank">Pelican</a></li>
        </ul>
      </nav>

      <ul class="social">
        <li><a class="sc-GITHUB" href="https://github.com/puluto" target="_blank"><i class="fa fa-GITHUB"></i></a></li>
        <li><a class="sc-微博" href="http://weibo.com/u/1871671127" target="_blank"><i class="fa fa-微博"></i></a></li>
      </ul>
    </div>


  </aside>
  <main>

    <nav>
      <a href="http://puluto.github.io">    Home
</a>

      <a href="/archives.html">Archives</a>
      <a href="/categories.html">Categories</a>
      <a href="/tags.html">Tags</a>

      <a href="http://puluto.github.io/feeds/all.atom.xml">    Atom
</a>

    </nav>

<article class="single">
  <header>
    <h1 id="celeryjian-jie">Celery简介</h1>
    <p>
          Posted on 2015-01-03(六) in <a href="http://puluto.github.io/category/ren-wu-diao-du.html">任务调度</a>


        &#8226; 1 min read
    </p>
  </header>


  <div>
    <p>Celery(芹菜)是一个异步任务队列/基于分布式消息传递的作业队列。</p>
<p>Celery用于生产系统每天处理数以百万计的任务。</p>
<p>Celery是用Python编写的，但该协议可以在任何语言实现。它也可以与其他语言通过webhooks实现。</p>
<p>由于Celery 3.0系列对以前的系列进行了大量重构优化，现在开始使用就没必要研究旧版本了，所以此介绍以3.0.24的文档为基础。</p>
<h3>Celery的工作结构</h3>
<p>在使用Celery的时候要明白它的大致结构，Celery的结构非常简单，大致分为3个部分：</p>
<ol>
<li>worker部分负责任务的处理，即工作线程，在我的理解中工作线程就是你写的python代码，当然还包括python调用系统工具功能</li>
<li>broker部分负责任务消息的分发以及任务结果的存储，这部分任务主要由中间数据存储系统完成，比如消息队列服务器RabbitMQ、redis、
   Amazon SQS、MongoDB、IronMQ等或者关系型数据库，使用关系型数据库依赖sqlalchemy或者django的ORM</li>
<li>Celery主类，进行任务最开始的指派与执行控制，他可以是单独的python脚本，也可以和其他程序结合，应用到django或者flask等
   web框架里面以及你能想到的任何应用</li>
</ol>
<h3>Celery的安装</h3>
<p>Celery只是一个python包，所以可以通过pip或者easy_install安装,除此之外还需要安装broker的系统，我使用的是redis，除了安装redis以外还需要安装celery-with-redis</p>
<div class="highlight"><pre><span></span>pip install celery
pip install celery-with-redis
</pre></div>


<p>使用其他类型的broker请参见官方文档：<a href="http://docs.celeryproject.org/en/latest/getting-started/first-steps-with-celery.html#using-a-database">first-steps-with-celery.html#using-a-database</a></p>
<h3>Celery的初步使用</h3>
<p>启动celery之前先架设好broker服务，安装好redis后以默认方式启动就可以了。
连接方式为：redis://localhost:6379/0</p>
<p>接下来编写任务脚本tasks.py,这个脚本在worker部分和任务分发部分都需要用到：</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">celery</span> <span class="kn">import</span> <span class="n">Celery</span>

<span class="n">celery</span> <span class="o">=</span> <span class="n">Celery</span><span class="p">(</span><span class="s1">&#39;tasks&#39;</span><span class="p">,</span> <span class="n">broker</span><span class="o">=</span><span class="s1">&#39;redis://localhost:6379/0&#39;</span><span class="p">)</span>

<span class="nd">@celery.task</span>
<span class="k">def</span> <span class="nf">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span>
</pre></div>


<p>执行命令启动worker进行：</p>
<div class="highlight"><pre><span></span><span class="c1">#这个命令要在tasks.py文件目录运行，命令表示以worker模式启动一个名为tasks的APP</span>
<span class="c1">#worker的名称是test-worker1，一台服务器上可以启动多个worker，只要名称不同，</span>
<span class="c1">#启动好的worker会自动根据tasks.py的信息注册到broker服务中，等待分发任务。</span>

celery -A tasks worker --loglevel<span class="o">=</span>info --hostname<span class="o">=</span>test-worker1
</pre></div>


<p>执行任务,使用delay()放，如下：</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">tasks</span> <span class="kn">import</span> <span class="n">add</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">add</span><span class="o">.</span><span class="n">delay</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</pre></div>


<p>也可以使用apply_async()方法，把结果存储在类似broker的backend系统中，可以和broker在同一个服务中，
更改tasks.py中的实例化celery一行,加入backend参数：</p>
<div class="highlight"><pre><span></span><span class="n">celery</span> <span class="o">=</span> <span class="n">Celery</span><span class="p">(</span><span class="s1">&#39;tasks&#39;</span><span class="p">,</span> <span class="n">broker</span><span class="o">=</span><span class="s1">&#39;redis://localhost:6379/0&#39;</span><span class="p">,</span> <span class="n">backend</span><span class="o">=</span><span class="s1">&#39;redis://localhost:6379/0&#39;</span><span class="p">)</span>
</pre></div>


<p>重新执行任务，使用apply_async把结果存储下来，在需要的时候调用get()进行获取，如下：</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">tasks</span> <span class="kn">import</span> <span class="n">add</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">add</span><span class="o">.</span><span class="n">apply_async</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">result</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
</pre></div>


<h3>Celery配置</h3>
<p>Celery有很多全局变量，不配置的情况下取默认值，当我们需要配置的时候可以把所有的参数写到一个py文件中然后在
任务文件中进行加载，也可以直接用一个类写到任务文件中，还可以直接对celery类的conf对象直接进行update操作：</p>
<p>方法1，直接加载py文件celeryconfig.py:</p>
<div class="highlight"><pre><span></span><span class="n">BROKER_URL</span> <span class="o">=</span> <span class="s1">&#39;amqp://&#39;</span>
<span class="n">CELERY_RESULT_BACKEND</span> <span class="o">=</span> <span class="s1">&#39;amqp://&#39;</span>
<span class="n">CELERY_TASK_SERIALIZER</span> <span class="o">=</span> <span class="s1">&#39;json&#39;</span>
<span class="n">CELERY_RESULT_SERIALIZER</span> <span class="o">=</span> <span class="s1">&#39;json&#39;</span>
<span class="n">CELERY_TIMEZONE</span> <span class="o">=</span> <span class="s1">&#39;Europe/Oslo&#39;</span>
<span class="n">CELERY_ENABLE_UTC</span> <span class="o">=</span> <span class="bp">True</span>

<span class="kn">from</span> <span class="nn">celery</span> <span class="kn">import</span> <span class="n">Celery</span>

<span class="n">celery</span> <span class="o">=</span> <span class="n">Celery</span><span class="p">()</span>
<span class="n">celery</span><span class="o">.</span><span class="n">config_from_object</span><span class="p">(</span><span class="s1">&#39;celeryconfig&#39;</span><span class="p">)</span>
</pre></div>


<p>方法2，直接对conf进行update：</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">celery</span> <span class="kn">import</span> <span class="n">Celery</span>

<span class="n">celery</span> <span class="o">=</span> <span class="n">Celery</span><span class="p">()</span>
<span class="n">celery</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
<span class="n">CELERY_TASK_SERIALIZER</span><span class="o">=</span><span class="s1">&#39;json&#39;</span><span class="p">,</span>
<span class="n">CELERY_RESULT_SERIALIZER</span><span class="o">=</span><span class="s1">&#39;json&#39;</span><span class="p">,</span>
<span class="n">CELERY_TIMEZONE</span><span class="o">=</span><span class="s1">&#39;Europe/Oslo&#39;</span><span class="p">,</span>
<span class="n">CELERY_ENABLE_UTC</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="ow">or</span>

<span class="n">celery</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">CELERY_TASK_SERIALIZER</span> <span class="o">=</span> <span class="s1">&#39;json&#39;</span>
</pre></div>


<p>方法3，直接加载类或对象:</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">celery</span> <span class="kn">import</span> <span class="n">Celery</span>

<span class="n">celery</span> <span class="o">=</span> <span class="n">Celery</span><span class="p">()</span>

<span class="k">class</span> <span class="nc">Config</span><span class="p">:</span>
    <span class="n">CELERY_ENABLE_UTC</span> <span class="o">=</span> <span class="bp">True</span>
    <span class="n">CELERY_TIMEZONE</span> <span class="o">=</span> <span class="s1">&#39;Europe/London&#39;</span>

<span class="n">celery</span><span class="o">.</span><span class="n">config_from_object</span><span class="p">(</span><span class="n">Config</span><span class="p">)</span>
</pre></div>


<h3>Celery任务分发控制</h3>
<p>在celery里面任务分发控制叫task routing即任务路由</p>
<p>celery的分发控制使用比较简单，但是高级功能比较复杂，我还不能完全理解，就介绍一下最基础的任务路由方法。</p>
<p>在worker进程启动的时候可以使用参数-Q指定当前worker所能接受的队列消息：</p>
<div class="highlight"><pre><span></span>celery -A tasks.tasks worker --loglevel=info --hostname=testq-worker -Q &#39;testq&#39;
</pre></div>


<p>然后在任务分发的过程中，调用apply_async或者delay方法中指定queue参数，当queue与worker的-Q相匹配时任务
就可以被分发到相应的worker进程中：</p>
<div class="highlight"><pre><span></span><span class="o">&gt;&gt;&gt;</span> <span class="kn">from</span> <span class="nn">tasks</span> <span class="kn">import</span> <span class="n">add</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">add</span><span class="o">.</span><span class="n">apply_async</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">queue</span><span class="o">=</span><span class="s1">&#39;testq&#39;</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">result</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
</pre></div>


<p>更高级的使用方法请大家研究官网的文档：
<a href="http://docs.celeryproject.org/en/latest/userguide/routing.html">docs-routing</a></p>
<h3>Celery的管理</h3>
<p>celery的管理有几种方式，比较直观的有一个叫flower的webui，可以提供任务查询，worker的生命管理以及路由管理，可以在界面上
进行实时的路由key添加（就是在worker启动时-Q参数指定的值）</p>
<p>使用方式为：</p>
<div class="highlight"><pre><span></span>pip install flower
celery flower --port<span class="o">=</span><span class="m">5555</span> --broker<span class="o">=</span>redis://localhost:6379/0
</pre></div>


<p>访问<a href="http://flower-server:5555">http://flower-server:5555</a></p>
<p>还有一种对任务进行实时监控的方式为celery本身提供的events的功能，启动方式为：</p>
<div class="highlight"><pre><span></span>celery events --broker<span class="o">=</span>redis://localhost:6379/0
</pre></div>


<h2>结束语</h2>
<p>celery还有很多功能没来得及研究，我准备把celery应用于服务器管理中一些任务的执行，来代替linux的crontab和一些手工操作，提升更强的灵活性以及更加直观</p>
  </div>
  <div class="tag-cloud">
    <p>
      <a href="http://puluto.github.io/tag/python.html">python</a>
      <a href="http://puluto.github.io/tag/celery.html">celery</a>
    </p>
  </div>




</article>

    <footer>
<p>
  &copy; Puluto 2016 - This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>
</p>
<p>    Powered by <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a>
</p><p>
  <a rel="license"
     href="http://creativecommons.org/licenses/by-sa/4.0/"
     target="_blank">
    <img alt="Creative Commons License"
         title="Creative Commons License"
         style="border-width:0"
         src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png"
         width="80"
         height="15"/>
  </a>
</p>    </footer>
  </main>

<!-- Google Analytics -->
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-63906522-1', 'auto');
  ga('send', 'pageview');
</script>
<!-- End Google Analytics -->



<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Thinking ",
  "url" : "http://puluto.github.io",
  "image": "",
  "description": ""
}
</script>
</body>
</html>